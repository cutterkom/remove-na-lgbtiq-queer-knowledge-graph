{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train NER with manually annotated data\n",
    "\n",
    "## Import data from rubrix\n",
    "\n",
    "I manually annotated data in rubrix, `status:Validated`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-13 17:10:25.690 | WARNING  | rubrix.client.rubrix_client:load:310 - The argument 'as_pandas' in `rb.load` will be deprecated in the future, and we will always return a `Dataset`. To emulate the future behavior set `as_pandas=False`. To get a pandas DataFrame, call `Dataset.to_pandas()`\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>prediction</th>\n",
       "      <th>prediction_agent</th>\n",
       "      <th>annotation</th>\n",
       "      <th>annotation_agent</th>\n",
       "      <th>id</th>\n",
       "      <th>metadata</th>\n",
       "      <th>status</th>\n",
       "      <th>event_timestamp</th>\n",
       "      <th>metrics</th>\n",
       "      <th>search_keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Teestube - In der Pestalozzistraße 20 Rgb. erö...</td>\n",
       "      <td>[Teestube, -, In, der, Pestalozzistraße, 20, R...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[(LOC, 0, 8), (ADR, 18, 37), (ADR, 104, 121), ...</td>\n",
       "      <td>rubrix</td>\n",
       "      <td>00f2ae40-e155-4f98-adaa-61d1db5a08ff</td>\n",
       "      <td>{'date': '22. Juni 1974', 'year': 1974, 'id': ...</td>\n",
       "      <td>Validated</td>\n",
       "      <td>None</td>\n",
       "      <td>{'text_length': 350, 'tokens': [{'idx': 0, 'va...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelheid Lissmann - Adelheid Lissmann, geb. 19...</td>\n",
       "      <td>[Adelheid, Lissmann, -, Adelheid, Lissmann, ,,...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[(PER, 0, 17), (ORG, 74, 95)]</td>\n",
       "      <td>rubrix</td>\n",
       "      <td>01a4910f-1088-413a-8879-55f06ded5d20</td>\n",
       "      <td>{'date': '1946', 'year': 1946, 'id': 12}</td>\n",
       "      <td>Validated</td>\n",
       "      <td>None</td>\n",
       "      <td>{'text_length': 192, 'tokens': [{'idx': 0, 'va...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Beschlagnahmen - Beschlagnahme der Blätter für...</td>\n",
       "      <td>[Beschlagnahmen, -, Beschlagnahme, der, Blätte...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[(PUBLICATION, 35, 60), (PUBLICATION, 71, 90)]</td>\n",
       "      <td>rubrix</td>\n",
       "      <td>029c88d4-bda1-4e3c-af72-85e516588301</td>\n",
       "      <td>{'date': '1925', 'year': 1925, 'id': 28}</td>\n",
       "      <td>Validated</td>\n",
       "      <td>None</td>\n",
       "      <td>{'text_length': 266, 'tokens': [{'idx': 0, 'va...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lesbenfrühlings­treffen - Das Lesbenfrühlingst...</td>\n",
       "      <td>[Lesbenfrühlings­treffen, -, Das, Lesbenfrühli...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[(EVENT, 0, 23), (EVENT, 30, 52), (EVENT, 61, ...</td>\n",
       "      <td>rubrix</td>\n",
       "      <td>02c3041b-6122-4f61-aa1e-26001b2cc865</td>\n",
       "      <td>{'date': '24. – 27. Mai 1996', 'year': 1996, '...</td>\n",
       "      <td>Validated</td>\n",
       "      <td>None</td>\n",
       "      <td>{'text_length': 210, 'tokens': [{'idx': 0, 'va...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Moby Dyke - Die Kunstaktion „Moby Dyke Lesbian...</td>\n",
       "      <td>[Moby, Dyke, -, Die, Kunstaktion, „, Moby, Dyk...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[(PER, 56, 70), (PER, 75, 93), (LOC, 118, 138)...</td>\n",
       "      <td>rubrix</td>\n",
       "      <td>03bf56b1-0857-47fc-9588-5caf5929847e</td>\n",
       "      <td>{'date': '21. – 22. August 2015', 'year': 2015...</td>\n",
       "      <td>Validated</td>\n",
       "      <td>None</td>\n",
       "      <td>{'text_length': 193, 'tokens': [{'idx': 0, 'va...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Teestube - In der Pestalozzistraße 20 Rgb. erö...   \n",
       "1  Adelheid Lissmann - Adelheid Lissmann, geb. 19...   \n",
       "2  Beschlagnahmen - Beschlagnahme der Blätter für...   \n",
       "3  Lesbenfrühlings­treffen - Das Lesbenfrühlingst...   \n",
       "4  Moby Dyke - Die Kunstaktion „Moby Dyke Lesbian...   \n",
       "\n",
       "                                              tokens prediction  \\\n",
       "0  [Teestube, -, In, der, Pestalozzistraße, 20, R...       None   \n",
       "1  [Adelheid, Lissmann, -, Adelheid, Lissmann, ,,...       None   \n",
       "2  [Beschlagnahmen, -, Beschlagnahme, der, Blätte...       None   \n",
       "3  [Lesbenfrühlings­treffen, -, Das, Lesbenfrühli...       None   \n",
       "4  [Moby, Dyke, -, Die, Kunstaktion, „, Moby, Dyk...       None   \n",
       "\n",
       "  prediction_agent                                         annotation  \\\n",
       "0             None  [(LOC, 0, 8), (ADR, 18, 37), (ADR, 104, 121), ...   \n",
       "1             None                      [(PER, 0, 17), (ORG, 74, 95)]   \n",
       "2             None     [(PUBLICATION, 35, 60), (PUBLICATION, 71, 90)]   \n",
       "3             None  [(EVENT, 0, 23), (EVENT, 30, 52), (EVENT, 61, ...   \n",
       "4             None  [(PER, 56, 70), (PER, 75, 93), (LOC, 118, 138)...   \n",
       "\n",
       "  annotation_agent                                    id  \\\n",
       "0           rubrix  00f2ae40-e155-4f98-adaa-61d1db5a08ff   \n",
       "1           rubrix  01a4910f-1088-413a-8879-55f06ded5d20   \n",
       "2           rubrix  029c88d4-bda1-4e3c-af72-85e516588301   \n",
       "3           rubrix  02c3041b-6122-4f61-aa1e-26001b2cc865   \n",
       "4           rubrix  03bf56b1-0857-47fc-9588-5caf5929847e   \n",
       "\n",
       "                                            metadata     status  \\\n",
       "0  {'date': '22. Juni 1974', 'year': 1974, 'id': ...  Validated   \n",
       "1           {'date': '1946', 'year': 1946, 'id': 12}  Validated   \n",
       "2           {'date': '1925', 'year': 1925, 'id': 28}  Validated   \n",
       "3  {'date': '24. – 27. Mai 1996', 'year': 1996, '...  Validated   \n",
       "4  {'date': '21. – 22. August 2015', 'year': 2015...  Validated   \n",
       "\n",
       "  event_timestamp                                            metrics  \\\n",
       "0            None  {'text_length': 350, 'tokens': [{'idx': 0, 'va...   \n",
       "1            None  {'text_length': 192, 'tokens': [{'idx': 0, 'va...   \n",
       "2            None  {'text_length': 266, 'tokens': [{'idx': 0, 'va...   \n",
       "3            None  {'text_length': 210, 'tokens': [{'idx': 0, 'va...   \n",
       "4            None  {'text_length': 193, 'tokens': [{'idx': 0, 'va...   \n",
       "\n",
       "  search_keywords  \n",
       "0            None  \n",
       "1            None  \n",
       "2            None  \n",
       "3            None  \n",
       "4            None  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "import rubrix as rb\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "\n",
    "# load rubrix dataset\n",
    "dataset_rb = rb.load('chronik_annotations', query=\"status:Validated\")\n",
    "dataset_rb.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Teestube - In der Pestalozzistraße 20 Rgb. erö...</td>\n",
       "      <td>[(LOC, 0, 8), (ADR, 18, 37), (ADR, 104, 121), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelheid Lissmann - Adelheid Lissmann, geb. 19...</td>\n",
       "      <td>[(PER, 0, 17), (ORG, 74, 95)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Beschlagnahmen - Beschlagnahme der Blätter für...</td>\n",
       "      <td>[(PUBLICATION, 35, 60), (PUBLICATION, 71, 90)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lesbenfrühlings­treffen - Das Lesbenfrühlingst...</td>\n",
       "      <td>[(EVENT, 0, 23), (EVENT, 30, 52), (EVENT, 61, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Moby Dyke - Die Kunstaktion „Moby Dyke Lesbian...</td>\n",
       "      <td>[(PER, 56, 70), (PER, 75, 93), (LOC, 118, 138)...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Teestube - In der Pestalozzistraße 20 Rgb. erö...   \n",
       "1  Adelheid Lissmann - Adelheid Lissmann, geb. 19...   \n",
       "2  Beschlagnahmen - Beschlagnahme der Blätter für...   \n",
       "3  Lesbenfrühlings­treffen - Das Lesbenfrühlingst...   \n",
       "4  Moby Dyke - Die Kunstaktion „Moby Dyke Lesbian...   \n",
       "\n",
       "                                               label  \n",
       "0  [(LOC, 0, 8), (ADR, 18, 37), (ADR, 104, 121), ...  \n",
       "1                      [(PER, 0, 17), (ORG, 74, 95)]  \n",
       "2     [(PUBLICATION, 35, 60), (PUBLICATION, 71, 90)]  \n",
       "3  [(EVENT, 0, 23), (EVENT, 30, 52), (EVENT, 61, ...  \n",
       "4  [(PER, 56, 70), (PER, 75, 93), (LOC, 118, 138)...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select text input and the annotated label\n",
    "# https://github.com/recognai/rubrix#3-load-and-create-a-training-set\n",
    "train_df = pd.DataFrame({\n",
    "    \"text\": dataset_rb.text,\n",
    "    \"label\": dataset_rb.annotation,\n",
    "})\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Training data\n",
    "\n",
    "### Transform rubrix format to spacy format\n",
    "\n",
    "I need to do some minor data transformation, because rubrix exports the annotated information as `(label, start, end)`, but Spacy needs `(start, end, label)`.\n",
    "\n",
    "So iterate over the data frame and change the order and save the data as TRAIN_DATA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TRAIN_DATA = []\n",
    "\n",
    "for record in train_df.index:\n",
    "    entities = []\n",
    "    text = train_df[\"text\"][record]\n",
    "    labels = train_df[\"label\"][record]\n",
    "    \n",
    "    for label in labels:\n",
    "        \n",
    "        start = label[1]\n",
    "        end = label[2]\n",
    "        label = label[0]\n",
    "        # switch position\n",
    "        entity = text, label, start, end\n",
    "        entities.append((start, end, label))\n",
    "\n",
    "    TRAIN_DATA.append([(text, entities)])\n",
    "\n",
    "# print(TRAIN_DATA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create spacy Doc object\n",
    "\n",
    "Prepare the data for training following the official tutorial: https://spacy.io/usage/training#training-data\n",
    "\n",
    "> For example, if you’re creating an NER pipeline, loading your annotations and setting them as the .ents property on a Doc is all you need to worry about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 132/132 [00:00<00:00, 1810.73it/s]\n"
     ]
    }
   ],
   "source": [
    "from spacy.tokens import DocBin\n",
    "\n",
    "nlp = spacy.blank(\"de\")\n",
    "\n",
    "# the DocBin will store the example documents\n",
    "doc_bin = DocBin(attrs=[\"ENT_IOB\", \"ENT_TYPE\"])  # we're just concerned with NER\n",
    "\n",
    "for record in tqdm(TRAIN_DATA):\n",
    "    \n",
    "    # text are class list, need to be transformed to character\n",
    "    text = \" \".join(map(str,[el[0] for el in record]))\n",
    "    doc = nlp(text)\n",
    "\n",
    "    annotations = [item[1] for item in record]\n",
    "    # print(\"annotations:\")\n",
    "    # print(annotations)\n",
    "    ents = []\n",
    "    \n",
    "    for annotation in annotations[0]:\n",
    "        # add start, end and label as spans\n",
    "        start = annotation[0]\n",
    "        end = annotation[1]\n",
    "        label = annotation[2]\n",
    "        span = doc.char_span(start, end, label=label)\n",
    "        \n",
    "        ents.append(span)\n",
    "    doc.ents = ents\n",
    "    #print(doc.ents)\n",
    "    doc_bin.add(doc)\n",
    "\n",
    "# no worries, i know this is dumb... \n",
    "doc_bin.to_disk(\"data/train.spacy\")\n",
    "doc_bin.to_disk(\"data/valid.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python -m spacy debug-data de ./train.spacy -p ner -b de_core_news_md\n",
    "\n",
    "python3 -m spacy debug data data-gathering/named-entity-recognition/train.spacy\n",
    "python3 -m spacy debug data ./train.spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use a spacy config file\n",
    "- https://ner.pythonhumanities.com/03_02_train_spacy_ner_model.html#what-is-the-spacy-config-cfg-file-and-how-do-i-create-it\n",
    "- base config file from: https://github.com/wjbmattingly/holocaust_ner_lessons/blob/main/data/config.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
      "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
      "data/config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    }
   ],
   "source": [
    "!python3 -m spacy init fill-config data/spacy-base-config.cfg data/config.cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validate training data based on config file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;3m⚠ The debug-data command is now available via the 'debug data'\n",
      "subcommand (without the hyphen). You can run python -m spacy debug --help for an\n",
      "overview of the other available debugging commands.\u001b[0m\n",
      "\u001b[1m\n",
      "============================ Data file validation ============================\u001b[0m\n",
      "\u001b[38;5;2m✔ Pipeline can be initialized with data\u001b[0m\n",
      "\u001b[38;5;2m✔ Corpus is loadable\u001b[0m\n",
      "\u001b[1m\n",
      "=============================== Training stats ===============================\u001b[0m\n",
      "Language: de\n",
      "Training pipeline: tok2vec, ner\n",
      "132 training docs\n",
      "132 evaluation docs\n",
      "\u001b[38;5;3m⚠ 132 training examples also in evaluation data\u001b[0m\n",
      "\u001b[38;5;3m⚠ Low number of examples to train a new pipeline (132)\u001b[0m\n",
      "\u001b[1m\n",
      "============================== Vocab & Vectors ==============================\u001b[0m\n",
      "\u001b[38;5;4mℹ 5900 total word(s) in the data (2019 unique)\u001b[0m\n",
      "\u001b[38;5;4mℹ No word vectors present in the package\u001b[0m\n",
      "\u001b[1m\n",
      "========================== Named Entity Recognition ==========================\u001b[0m\n",
      "\u001b[38;5;4mℹ 15 label(s)\u001b[0m\n",
      "0 missing value(s) (tokens with '-' label)\n",
      "\u001b[38;5;3m⚠ Low number of examples for label 'Slogan' (7)\u001b[0m\n",
      "\u001b[2K\u001b[38;5;3m⚠ Low number of examples for label 'EVENT' (43)\u001b[0m\n",
      "\u001b[2K\u001b[38;5;3m⚠ Low number of examples for label 'CITY' (25)\u001b[0m\n",
      "\u001b[2K\u001b[38;5;3m⚠ Low number of examples for label 'DATE' (22)\u001b[0m\n",
      "\u001b[2K\u001b[38;5;3m⚠ Low number of examples for label 'LAW' (34)\u001b[0m\n",
      "\u001b[2K\u001b[38;5;3m⚠ Low number of examples for label 'AWARD' (6)\u001b[0m\n",
      "\u001b[2K\u001b[38;5;3m⚠ Low number of examples for label 'PARTY' (10)\u001b[0m\n",
      "\u001b[2K\u001b[38;5;3m⚠ Low number of examples for label 'COUNTRY' (22)\u001b[0m\n",
      "\u001b[2K\u001b[38;5;3m⚠ Low number of examples for label 'ADR' (15)\u001b[0m\n",
      "\u001b[2K\u001b[38;5;3m⚠ Low number of examples for label 'PUBLICATION' (16)\u001b[0m\n",
      "\u001b[2K\u001b[38;5;3m⚠ Low number of examples for label 'MOVEMENT' (3)\u001b[0m\n",
      "\u001b[2K\u001b[38;5;2m✔ Examples without occurrences available for all labels\u001b[0m\n",
      "\u001b[38;5;2m✔ No entities consisting of or starting/ending with whitespace\u001b[0m\n",
      "\u001b[38;5;2m✔ No entities crossing sentence boundaries\u001b[0m\n",
      "\u001b[1m\n",
      "================================== Summary ==================================\u001b[0m\n",
      "\u001b[38;5;2m✔ 5 checks passed\u001b[0m\n",
      "\u001b[38;5;3m⚠ 13 warnings\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# check data \n",
    "!python3 -m spacy debug-data data/config.cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Created output directory: models/output\u001b[0m\n",
      "\u001b[38;5;4mℹ Saving to output directory: models/output\u001b[0m\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[2022-04-13 17:37:32,419] [INFO] Set up nlp object from config\n",
      "[2022-04-13 17:37:32,424] [INFO] Pipeline: ['tok2vec', 'ner']\n",
      "[2022-04-13 17:37:32,426] [INFO] Created vocabulary\n",
      "[2022-04-13 17:37:32,426] [INFO] Finished initializing nlp object\n",
      "[2022-04-13 17:37:32,744] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     27.74    0.81    0.44    5.06    0.01\n",
      "  2     200        764.60   2841.59   40.31   45.79   35.99    0.40\n",
      "  6     400       2359.37   2282.67   76.03   78.47   73.74    0.76\n",
      " 11     600       1550.19   1398.56   94.04   94.50   93.58    0.94\n",
      " 17     800       4459.26    769.20   96.79   96.88   96.69    0.97\n",
      " 24    1000        786.10    347.96   99.51   99.42   99.61    1.00\n",
      " 33    1200        653.55    222.39   99.71   99.81   99.61    1.00\n",
      " 45    1400        793.36    227.56   99.81   99.81   99.81    1.00\n",
      " 59    1600       1073.20    151.27  100.00  100.00  100.00    1.00\n",
      " 76    1800       3979.36    130.67   99.71   99.61   99.81    1.00\n",
      " 97    2000        583.97    107.49  100.00  100.00  100.00    1.00\n",
      "124    2200        599.32     72.88  100.00  100.00  100.00    1.00\n",
      "156    2400        335.89     77.16  100.00  100.00  100.00    1.00\n",
      "189    2600        381.68     38.06  100.00  100.00  100.00    1.00\n",
      "222    2800       1989.68     98.01  100.00  100.00  100.00    1.00\n",
      "256    3000        369.97     50.72  100.00  100.00  100.00    1.00\n",
      "289    3200        382.65     33.63  100.00  100.00  100.00    1.00\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "models/output/model-last\n"
     ]
    }
   ],
   "source": [
    "!python3 -m spacy train data/config.cfg --output ./models/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rosa Liste PARTY\n",
      "AK Uferlos ORG\n",
      "Marion Hölczl EVENT\n",
      "Rosa-Liste-Bezirksrätin EVENT\n",
      "Altstadt-Lehel. ORG\n"
     ]
    }
   ],
   "source": [
    "trained_nlp = spacy.load(\"models/output/model-best\")\n",
    "text = 'Die Rosa Liste öffnet sich den Lesben: „Rosa Liste – jetzt lesbisch-schwul?“, eine Veranstaltung organisiert vom AK Uferlos. In der folgenden Stadtratswahl 1994 treten sowohl schwule als auch lesbische KandidatInnen an; Marion Hölczl war bereits ab 1992 Rosa-Liste-Bezirksrätin in Altstadt-Lehel.'\n",
    "doc = trained_nlp(text)\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print (ent.text, ent.label_)\n",
    "if len(doc.ents) == 0:\n",
    "    print (\"No entities found.\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e24addbd1c21af059ce21653e18ac38406b3fe69eeb60448b8d4120b64cb5797"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
