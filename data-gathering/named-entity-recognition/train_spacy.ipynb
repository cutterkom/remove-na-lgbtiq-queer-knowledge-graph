{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>prediction</th>\n",
       "      <th>prediction_agent</th>\n",
       "      <th>annotation</th>\n",
       "      <th>annotation_agent</th>\n",
       "      <th>id</th>\n",
       "      <th>metadata</th>\n",
       "      <th>status</th>\n",
       "      <th>event_timestamp</th>\n",
       "      <th>metrics</th>\n",
       "      <th>search_keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Teestube - In der Pestalozzistraße 20 Rgb. erö...</td>\n",
       "      <td>[Teestube, -, In, der, Pestalozzistraße, 20, R...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[(LOC, 0, 8), (ADR, 18, 37), (ADR, 104, 121), ...</td>\n",
       "      <td>rubrix</td>\n",
       "      <td>00f2ae40-e155-4f98-adaa-61d1db5a08ff</td>\n",
       "      <td>{'date': '22. Juni 1974', 'year': 1974, 'id': ...</td>\n",
       "      <td>Validated</td>\n",
       "      <td>None</td>\n",
       "      <td>{'text_length': 350, 'tokens': [{'idx': 0, 'va...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelheid Lissmann - Adelheid Lissmann, geb. 19...</td>\n",
       "      <td>[Adelheid, Lissmann, -, Adelheid, Lissmann, ,,...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[(PER, 0, 17), (ORG, 74, 95)]</td>\n",
       "      <td>rubrix</td>\n",
       "      <td>01a4910f-1088-413a-8879-55f06ded5d20</td>\n",
       "      <td>{'date': '1946', 'year': 1946, 'id': 12}</td>\n",
       "      <td>Validated</td>\n",
       "      <td>None</td>\n",
       "      <td>{'text_length': 192, 'tokens': [{'idx': 0, 'va...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Beschlagnahmen - Beschlagnahme der Blätter für...</td>\n",
       "      <td>[Beschlagnahmen, -, Beschlagnahme, der, Blätte...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[(PUBLICATION, 35, 60), (PUBLICATION, 71, 90)]</td>\n",
       "      <td>rubrix</td>\n",
       "      <td>029c88d4-bda1-4e3c-af72-85e516588301</td>\n",
       "      <td>{'date': '1925', 'year': 1925, 'id': 28}</td>\n",
       "      <td>Validated</td>\n",
       "      <td>None</td>\n",
       "      <td>{'text_length': 266, 'tokens': [{'idx': 0, 'va...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lesbenfrühlings­treffen - Das Lesbenfrühlingst...</td>\n",
       "      <td>[Lesbenfrühlings­treffen, -, Das, Lesbenfrühli...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[(EVENT, 0, 23), (EVENT, 30, 52), (EVENT, 61, ...</td>\n",
       "      <td>rubrix</td>\n",
       "      <td>02c3041b-6122-4f61-aa1e-26001b2cc865</td>\n",
       "      <td>{'date': '24. – 27. Mai 1996', 'year': 1996, '...</td>\n",
       "      <td>Validated</td>\n",
       "      <td>None</td>\n",
       "      <td>{'text_length': 210, 'tokens': [{'idx': 0, 'va...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Moby Dyke - Die Kunstaktion „Moby Dyke Lesbian...</td>\n",
       "      <td>[Moby, Dyke, -, Die, Kunstaktion, „, Moby, Dyk...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[(PER, 56, 70), (PER, 75, 93), (LOC, 118, 138)...</td>\n",
       "      <td>rubrix</td>\n",
       "      <td>03bf56b1-0857-47fc-9588-5caf5929847e</td>\n",
       "      <td>{'date': '21. – 22. August 2015', 'year': 2015...</td>\n",
       "      <td>Validated</td>\n",
       "      <td>None</td>\n",
       "      <td>{'text_length': 193, 'tokens': [{'idx': 0, 'va...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Teestube - In der Pestalozzistraße 20 Rgb. erö...   \n",
       "1  Adelheid Lissmann - Adelheid Lissmann, geb. 19...   \n",
       "2  Beschlagnahmen - Beschlagnahme der Blätter für...   \n",
       "3  Lesbenfrühlings­treffen - Das Lesbenfrühlingst...   \n",
       "4  Moby Dyke - Die Kunstaktion „Moby Dyke Lesbian...   \n",
       "\n",
       "                                              tokens prediction  \\\n",
       "0  [Teestube, -, In, der, Pestalozzistraße, 20, R...       None   \n",
       "1  [Adelheid, Lissmann, -, Adelheid, Lissmann, ,,...       None   \n",
       "2  [Beschlagnahmen, -, Beschlagnahme, der, Blätte...       None   \n",
       "3  [Lesbenfrühlings­treffen, -, Das, Lesbenfrühli...       None   \n",
       "4  [Moby, Dyke, -, Die, Kunstaktion, „, Moby, Dyk...       None   \n",
       "\n",
       "  prediction_agent                                         annotation  \\\n",
       "0             None  [(LOC, 0, 8), (ADR, 18, 37), (ADR, 104, 121), ...   \n",
       "1             None                      [(PER, 0, 17), (ORG, 74, 95)]   \n",
       "2             None     [(PUBLICATION, 35, 60), (PUBLICATION, 71, 90)]   \n",
       "3             None  [(EVENT, 0, 23), (EVENT, 30, 52), (EVENT, 61, ...   \n",
       "4             None  [(PER, 56, 70), (PER, 75, 93), (LOC, 118, 138)...   \n",
       "\n",
       "  annotation_agent                                    id  \\\n",
       "0           rubrix  00f2ae40-e155-4f98-adaa-61d1db5a08ff   \n",
       "1           rubrix  01a4910f-1088-413a-8879-55f06ded5d20   \n",
       "2           rubrix  029c88d4-bda1-4e3c-af72-85e516588301   \n",
       "3           rubrix  02c3041b-6122-4f61-aa1e-26001b2cc865   \n",
       "4           rubrix  03bf56b1-0857-47fc-9588-5caf5929847e   \n",
       "\n",
       "                                            metadata     status  \\\n",
       "0  {'date': '22. Juni 1974', 'year': 1974, 'id': ...  Validated   \n",
       "1           {'date': '1946', 'year': 1946, 'id': 12}  Validated   \n",
       "2           {'date': '1925', 'year': 1925, 'id': 28}  Validated   \n",
       "3  {'date': '24. – 27. Mai 1996', 'year': 1996, '...  Validated   \n",
       "4  {'date': '21. – 22. August 2015', 'year': 2015...  Validated   \n",
       "\n",
       "  event_timestamp                                            metrics  \\\n",
       "0            None  {'text_length': 350, 'tokens': [{'idx': 0, 'va...   \n",
       "1            None  {'text_length': 192, 'tokens': [{'idx': 0, 'va...   \n",
       "2            None  {'text_length': 266, 'tokens': [{'idx': 0, 'va...   \n",
       "3            None  {'text_length': 210, 'tokens': [{'idx': 0, 'va...   \n",
       "4            None  {'text_length': 193, 'tokens': [{'idx': 0, 'va...   \n",
       "\n",
       "  search_keywords  \n",
       "0            None  \n",
       "1            None  \n",
       "2            None  \n",
       "3            None  \n",
       "4            None  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "import rubrix as rb\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# load rubrix dataset\n",
    "# select text input and the annotated label\n",
    "# https://github.com/recognai/rubrix#3-load-and-create-a-training-set\n",
    "dataset_rb = rb.load('chronik_annotations', query=\"status:Validated\")\n",
    "dataset_rb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "The data needs two steps of preprocessing:\n",
    "\n",
    "1. Convert `rubrix` to `spacy` format for annotations, because `rubrix` exports the annotated information as `(label, start, end)`, but `spacy` needs `(start, end, label)`. See: `convert_rubrix_to_spacy()`.\n",
    "2. Convert annotations to a `DocBin` and save file to disk. See `create_doc_bin()`\n",
    "\n",
    "\n",
    "[More infos in official Documentation](https://spacy.io/usage/training#training-data):\n",
    "\n",
    "> For example, if you’re creating an NER pipeline, loading your annotations and setting them as the .ents property on a Doc is all you need to worry about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_rubrix_to_spacy(rubrix_name:str, query:str):\n",
    "    \"\"\"\n",
    "    import annotated data from rubrix and transform it to spacy flavour\n",
    "    @name name of rubrix dataset to import\n",
    "    @query query rubrix data, typically \"status:Validated\"\n",
    "    \"\"\"\n",
    "    # load rubrix dataset\n",
    "    labeled_data = rb.load(rubrix_name, query=query)\n",
    "\n",
    "    labeled_data_df = pd.DataFrame({\n",
    "        \"text\": labeled_data.text,\n",
    "        \"label\": labeled_data.annotation,\n",
    "    })\n",
    "    \n",
    "    training_data = []\n",
    "\n",
    "    for record in labeled_data_df.index:\n",
    "        entities = []\n",
    "        text = labeled_data_df[\"text\"][record]\n",
    "        labels = labeled_data_df[\"label\"][record]\n",
    "        \n",
    "        for label in labels:\n",
    "            \n",
    "            start = label[1]\n",
    "            end = label[2]\n",
    "            label = label[0]\n",
    "            # switch position\n",
    "            entity = text, label, start, end\n",
    "            entities.append((start, end, label))\n",
    "\n",
    "        training_data.append([(text, entities)])\n",
    "    return(training_data)\n",
    "\n",
    "\n",
    "def create_doc_bin(data: list, lang: str):\n",
    "\n",
    "    nlp = spacy.blank(lang)\n",
    "\n",
    "    # the DocBin will store the documents\n",
    "    doc_bin = DocBin(attrs=[\"ENT_IOB\", \"ENT_TYPE\"])\n",
    "\n",
    "    for record in tqdm(data):\n",
    "        \n",
    "        # text are class list, need to be transformed to character\n",
    "        text = \" \".join(map(str,[el[0] for el in record]))\n",
    "        doc = nlp(text)\n",
    "\n",
    "        annotations = [item[1] for item in record]\n",
    "        # print(\"annotations:\")\n",
    "        # print(annotations)\n",
    "        ents = []\n",
    "        \n",
    "        for annotation in annotations[0]:\n",
    "            # add start, end and label as spans\n",
    "            start = annotation[0]\n",
    "            end = annotation[1]\n",
    "            label = annotation[2]\n",
    "            span = doc.char_span(start, end, label=label)\n",
    "            ents.append(span)\n",
    "        doc.ents = ents\n",
    "        doc_bin.add(doc)\n",
    "    return(doc_bin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing execution, split data in train and test (called `dev` here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [00:00<00:00, 1765.29it/s]\n",
      "100%|██████████| 27/27 [00:00<00:00, 1622.11it/s]\n"
     ]
    }
   ],
   "source": [
    "labeled_data = convert_rubrix_to_spacy(rubrix_name=\"chronik_annotations\", query=\"status:Validated\")\n",
    "\n",
    "train, dev = train_test_split(labeled_data, test_size=0.2) \n",
    "create_doc_bin(train, \"de\").to_disk(\"data/train.spacy\")\n",
    "create_doc_bin(dev, \"de\").to_disk(\"data/dev.spacy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use a spacy config file\n",
    "- https://ner.pythonhumanities.com/03_02_train_spacy_ner_model.html#what-is-the-spacy-config-cfg-file-and-how-do-i-create-it\n",
    "- base config file from: https://github.com/wjbmattingly/holocaust_ner_lessons/blob/main/data/config.cfg\n",
    "- Spacy Documentation about projects https://explosion.ai/blog/spacy-v3-project-config-systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;3m⚠ To generate a more effective transformer-based config (GPU-only),\n",
      "install the spacy-transformers package and re-run this command. The config\n",
      "generated now does not use transformers.\u001b[0m\n",
      "\u001b[38;5;4mℹ Generated config template specific for your use case\u001b[0m\n",
      "- Language: en\n",
      "- Pipeline: ner\n",
      "- Optimize for: efficiency\n",
      "- Hardware: CPU\n",
      "- Transformer: None\n",
      "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
      "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
      "data/base-config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train base-config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    }
   ],
   "source": [
    "# create base config\n",
    "!python3 -m spacy init config --pipeline ner data/base-config.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;3m⚠ Nothing to auto-fill: base config is already complete\u001b[0m\n",
      "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
      "data/config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    }
   ],
   "source": [
    "# fill with default values\n",
    "!python3 -m spacy init fill-config data/base-config.cfg data/config.cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validate training data based on config file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "============================ Data file validation ============================\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.9/3.9.10/Frameworks/Python.framework/Versions/3.9/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/homebrew/Cellar/python@3.9/3.9.10/Frameworks/Python.framework/Versions/3.9/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/kabr/code/remove-na-lgbtiq-queer-knowledge-graph/venv/lib/python3.9/site-packages/spacy/__main__.py\", line 4, in <module>\n",
      "    setup_cli()\n",
      "  File \"/Users/kabr/code/remove-na-lgbtiq-queer-knowledge-graph/venv/lib/python3.9/site-packages/spacy/cli/_util.py\", line 71, in setup_cli\n",
      "    command(prog_name=COMMAND)\n",
      "  File \"/Users/kabr/code/remove-na-lgbtiq-queer-knowledge-graph/venv/lib/python3.9/site-packages/click/core.py\", line 1128, in __call__\n",
      "    return self.main(*args, **kwargs)\n",
      "  File \"/Users/kabr/code/remove-na-lgbtiq-queer-knowledge-graph/venv/lib/python3.9/site-packages/click/core.py\", line 1053, in main\n",
      "    rv = self.invoke(ctx)\n",
      "  File \"/Users/kabr/code/remove-na-lgbtiq-queer-knowledge-graph/venv/lib/python3.9/site-packages/click/core.py\", line 1659, in invoke\n",
      "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
      "  File \"/Users/kabr/code/remove-na-lgbtiq-queer-knowledge-graph/venv/lib/python3.9/site-packages/click/core.py\", line 1659, in invoke\n",
      "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
      "  File \"/Users/kabr/code/remove-na-lgbtiq-queer-knowledge-graph/venv/lib/python3.9/site-packages/click/core.py\", line 1395, in invoke\n",
      "    return ctx.invoke(self.callback, **ctx.params)\n",
      "  File \"/Users/kabr/code/remove-na-lgbtiq-queer-knowledge-graph/venv/lib/python3.9/site-packages/click/core.py\", line 754, in invoke\n",
      "    return __callback(*args, **kwargs)\n",
      "  File \"/Users/kabr/code/remove-na-lgbtiq-queer-knowledge-graph/venv/lib/python3.9/site-packages/typer/main.py\", line 500, in wrapper\n",
      "    return callback(**use_params)  # type: ignore\n",
      "  File \"/Users/kabr/code/remove-na-lgbtiq-queer-knowledge-graph/venv/lib/python3.9/site-packages/spacy/cli/debug_data.py\", line 67, in debug_data_cli\n",
      "    debug_data(\n",
      "  File \"/Users/kabr/code/remove-na-lgbtiq-queer-knowledge-graph/venv/lib/python3.9/site-packages/spacy/cli/debug_data.py\", line 107, in debug_data\n",
      "    nlp.initialize(lambda: train_corpus(nlp))\n",
      "  File \"/Users/kabr/code/remove-na-lgbtiq-queer-knowledge-graph/venv/lib/python3.9/site-packages/spacy/language.py\", line 1308, in initialize\n",
      "    proc.initialize(get_examples, nlp=self, **p_settings)\n",
      "  File \"/Users/kabr/code/remove-na-lgbtiq-queer-knowledge-graph/venv/lib/python3.9/site-packages/spacy/pipeline/tok2vec.py\", line 215, in initialize\n",
      "    validate_get_examples(get_examples, \"Tok2Vec.initialize\")\n",
      "  File \"spacy/training/example.pyx\", line 65, in spacy.training.example.validate_get_examples\n",
      "  File \"spacy/training/example.pyx\", line 44, in spacy.training.example.validate_examples\n",
      "  File \"/Users/kabr/code/remove-na-lgbtiq-queer-knowledge-graph/venv/lib/python3.9/site-packages/spacy/training/corpus.py\", line 142, in __call__\n",
      "    for real_eg in examples:\n",
      "  File \"/Users/kabr/code/remove-na-lgbtiq-queer-knowledge-graph/venv/lib/python3.9/site-packages/spacy/training/corpus.py\", line 164, in make_examples\n",
      "    for reference in reference_docs:\n",
      "  File \"/Users/kabr/code/remove-na-lgbtiq-queer-knowledge-graph/venv/lib/python3.9/site-packages/spacy/training/corpus.py\", line 197, in read_docbin\n",
      "    doc_bin = DocBin().from_disk(loc)\n",
      "  File \"/Users/kabr/code/remove-na-lgbtiq-queer-knowledge-graph/venv/lib/python3.9/site-packages/spacy/tokens/_serialize.py\", line 271, in from_disk\n",
      "    with path.open(\"rb\") as file_:\n",
      "  File \"/opt/homebrew/Cellar/python@3.9/3.9.10/Frameworks/Python.framework/Versions/3.9/lib/python3.9/pathlib.py\", line 1252, in open\n",
      "    return io.open(self, mode, buffering, encoding, errors, newline,\n",
      "  File \"/opt/homebrew/Cellar/python@3.9/3.9.10/Frameworks/Python.framework/Versions/3.9/lib/python3.9/pathlib.py\", line 1120, in _opener\n",
      "    return self._accessor.open(self, flags, mode)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'data/train.spacy'\n"
     ]
    }
   ],
   "source": [
    "# check data \n",
    "!python3 -m spacy debug data data/config.cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m spacy train data/config.cfg --output ./models/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_nlp = spacy.load(\"models/output/model-best\")\n",
    "text = 'Die Rosa Liste öffnet sich den Lesben: „Rosa Liste – jetzt lesbisch-schwul?“, eine Veranstaltung organisiert vom AK Uferlos. In der folgenden Stadtratswahl 1994 treten sowohl schwule als auch lesbische KandidatInnen an; Marion Hölczl war bereits ab 1992 Rosa-Liste-Bezirksrätin in Altstadt-Lehel.'\n",
    "doc = trained_nlp(text)\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print (ent.text, ent.label_)\n",
    "if len(doc.ents) == 0:\n",
    "    print (\"No entities found.\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e24addbd1c21af059ce21653e18ac38406b3fe69eeb60448b8d4120b64cb5797"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
