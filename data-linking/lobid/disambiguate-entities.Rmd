---
title: "R Notebook"
output: html_notebook
---

```{r setup}
# title: Disambiguate found lobid entities
# desc: 
# input: 
# output: 

library(tidyverse)
library(kabrutils)

con <- connect_db("db_clean")

entities <- tbl(con, "entities") %>% 
  select(-contains("_at")) %>% 
  collect()

entities_per_type <- tbl(con, "entities_per_type") %>% collect()

DBI::dbDisconnect(con); rm(con)

con <- connect_db()

el_matches <- tbl(con, "el_matches") %>% 
  # maybe keep created_at b/c assumption that first matches per entity are the most specific
  select(-contains("combination"), -updated_at, -created_at) %>% 
  # remove topics of books
  filter(external_id_desc != "SubjectHeading") %>% 
  distinct() %>% 
  collect()

books_locations <-tbl(con, "books_wide") %>% 
  select(book_id, location) %>% 
  collect() %>% 
  inner_join(entities_per_type, by = "book_id") %>% 
  distinct(location, id)

DBI::dbDisconnect(con); rm(con)

# used to remove authors who seem to be organisations
string_mappings <- config::get(file = "../../static/string-mapping.yml")
```


## Create hierarchies of sources

Some of the sources are stricter than others

```{r}
matches <- entities %>% 
  left_join(el_matches, by = c("id" = "entity_id"), suffix = c("_db", "_lobid")) %>% 
  filter(!is.na(external_id)) %>% 
    mutate(
    hierarchy =
      case_when(
        source == "lobid via book isbn" ~ 1,
        source == "lobid via author name search" ~ 2,
        source == "lobid via author book search" ~ 3,
        source == "lobid via publisher in entity search" ~ 4,
        source == "lobid via entity search (softer: also non publisher category)" ~ 5,
        str_detect(source, "softer") ~ 5
      )
  ) %>% 
  filter(!name %in% c("München", "Landeshauptstadt München")) %>% 
  filter(!external_id_label %in% c("Österreich. Bundesministerium für Gesundheit"))
```

## Simiarilities zwischen Enititynamen und lobid Labels

```{r calc_string_similarites}
string_similarities <- matches %>% 
  distinct(id, external_id, name, external_id_label, hierarchy, external_id_desc) %>% 
  mutate(
    external_id_label_norm = str_remove_all(tolower(external_id_label), paste0(string_mappings$organisations_marker, collapse = "|")),
    name_norm = str_remove_all(tolower(name), paste0(string_mappings$organisations_marker, collapse = "|"))) %>% 
  rowwise() %>% 
  mutate(
    tokens_candidate_1 = create_fingerprint(name_norm),
    tokens_candidate_2 = create_fingerprint(external_id_label_norm),
    similarity = 1 - stringdist::stringdist(tokens_candidate_1, tokens_candidate_2, "jaccard"))
```

Keep with min hierarchy (= most precise search) and highest string similarity. 

Plus check for `lastname` when `person`. Removes false positives like `Pierre Seel` <-> `Gisel, Pierre`

```{r}
highest_similarity_by_id <- string_similarities %>% 
  group_by(id) %>% 
  filter(hierarchy == min(hierarchy)) %>% 
  filter(similarity == max(similarity)) %>% 
  ungroup() %>% 
  mutate(
    is_person = str_detect(external_id_desc, "Person"),
    lastname = ifelse(is_person == TRUE, str_extract(external_id_label, ".*(?=,)"), NA),
    has_lastname = ifelse(!is.na(lastname), str_detect(name, lastname), FALSE),
    lastname_check = 
      case_when(
        is_person == TRUE & has_lastname == TRUE ~ "passed",
        is_person == TRUE & has_lastname == FALSE ~ "not_passed",
        is_person == FALSE ~ "not_relevant"
      )
  ) %>% 
  filter(lastname_check != "not_passed")
```


```{r}
highest_similarity_by_id %>% filter(similarity >= 0.85)
```

```{r}
highest_similarity_by_id %>% filter(similarity == 1)
```
Entscheidung: Alles über `0.85` passed den Test (ein paar false positives sind natürlich dabei).

```{r}
keep_via_similarities <- highest_similarity_by_id %>% filter(similarity >= 0.85)
```

## Wie viele haben mehr als eine Zuweisung? 

```{r}
matches_count <- matches %>% count(id, name, sort = T)

matches_count %>% summary()
```


```{r}
matches_count %>% 
  ggplot(aes(n)) + geom_histogram() + theme_minimal()
```

Gibt also ein paar richtig krasse Ausreißer.
Aber das sind auch offensichtliche Allerwertsnamen bei Verlagen, das sollte sich über `.placeOfBusiness` bzw. Ort der Veröffentlichung zumindest z.T. auflösen lassen.

```{r}
matches_count %>% filter(n>1)
```

## Wie viele haben nur exakt eine zugewiesene GND ID?

```{r}
matches_count
```
## Wie veile haben nur eine einzige gnd_id?

Annahme: Wenn nur eine einzige `gnd_id` und die Zuweisung durch `lobid via book isbn` kommt, dann ist das korrekt.

```{r}
one_match <- matches_count %>% 
  filter(n == 1) %>% 
  left_join(matches, c("id", "name")) %>% 
  select(id, name, external_id, external_id_label, external_id_desc, source)
```

Verteilung auf `source`:

```{r}
one_match %>% count(source, sort = T)
```
Matches mit ?lobid via author book search` schauen auch ganz gut aus, aber es gibt auch false positives.

## Mehrere Matches

```{r}
more_matches <- matches_count %>% 
  filter(n > 1) %>% 
  left_join(matches, c("id", "name")) %>% 
  distinct(id, name, external_id_label, external_id, external_id_desc, source)
```



```{r}
more_matches %>% count(source, sort = T)
```

Manche werden in mehreren Suchen gefunden oder über mehrere Bücher, deshalb nochmal distincten:

```{r}
more_matches <- more_matches %>% 
  distinct(id, name, external_id_label, external_id, external_id_desc)

more_matches_count <- more_matches %>% 
  count(id, sort = T) %>% 
  left_join(more_matches, by = "id") %>% 
  left_join(string_similarities, by = c("id", "name", "external_id", "external_id_label", "external_id_desc"))
```

## Verlage: Check `location`

Ich habe die Info zu `.placeOfBusiness` gespeichert, um einen Abgleich mit dem Publikationsort der 

```{r}
more_matches_add_info <- more_matches_count %>% 
  left_join(el_matches %>% select(id = entity_id, external_id, additional_data), by = c("id", "external_id"))
```

```{r}
check_locations <- more_matches_add_info %>% 
  filter(!is.na(additional_data)) %>% 
  #sample_n(50) %>% 
  pmap_dfr(function(...) {
    current <- tibble(...)
    
    current %>% inner_join(books_locations, by = "id") %>% 
      mutate(has_location = str_detect(additional_data, location))
  }
  )

check_locations_true <- check_locations %>% filter(has_location == TRUE)
```

Location-Check eher enttäuschend von der Menge her, sind nur `nrow(check_locations_true)` Zeilen, dafür mindestens ein offensichtliches false positive (Berlin Museum).


```{r}
exakt_names_more_matches <- more_matches_count %>% 
  filter(similarity >= 0.85)
  
```

# Accepted Entities

```{r}
accepted <- bind_rows(
  # remove: too many false positives, e.g. Berlin Museum 
  #check_locations_true %>% distinct(id, external_id) %>% mutate(hierarchy = 1),
  one_match %>% filter(source == "lobid via book isbn") %>% distinct(id, external_id) %>% mutate(hierarchy = 1),
  keep_via_similarities %>% distinct(id, external_id) %>% mutate(hierarchy = 2)
) %>% left_join(matches %>% distinct(id, external_id, name, external_id_label, external_id_desc), by = c("id", "external_id"))

```

Auch GND_IDs sind mehrfach vergeben - how come? 

Gibt einfach gelegentlich mehr als eine GND_ID, manchmal zurecht, weil einfach mehrere IDs zu einer Entität existieren; oder halt Fehlmatch.

```{r}
accepted %>% count(id, sort = T) %>% filter(n>1) %>% left_join(matches) %>% View
```


Anteil der entities mit external_id

```{r}
nrow(accepted %>% distinct(id)) / nrow(entities)
```

# Persist in DB

Die Ergebnisse speichere ich in der DB zbl `lgbtiq_kg_clean.el_matches`.

```{r eval=FALSE}

import <- accepted %>% 
  distinct(id, external_id, hierarchy) %>% 
  inner_join(el_matches, by = c("id" = "entity_id", "external_id")) %>% 
  distinct()

create_table <- "
CREATE TABLE IF NOT EXISTS `el_matches` (
  `created_at` timestamp NULL DEFAULT current_timestamp(),
  `updated_at` timestamp NULL DEFAULT NULL ON UPDATE current_timestamp(),
  `id` varchar(55) NOT NULL,
  `entity_id_type` varchar(255) DEFAULT NULL,
  `entity_id_combination` varchar(255) DEFAULT NULL,
  `entity_id_combination_type` varchar(255) DEFAULT NULL,
  `external_id` varchar(255) DEFAULT NULL,
  `external_id_label` varchar(255) DEFAULT NULL,
  `external_id_type` varchar(55) NOT NULL,
  `external_id_desc` varchar(255) DEFAULT NULL,
  `source` varchar(255) DEFAULT NULL,
  `hierarchy` int(11) DEFAULT NULL, # new in clean
  `source_id` longtext DEFAULT NULL,
  `property_type` varchar(255) DEFAULT NULL,
  `additional_data` longtext CHARACTER SET utf8mb4 COLLATE utf8mb4_bin DEFAULT NULL CHECK (json_valid(`additional_data`))
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
"

con <- connect_db("db_clean")
DBI::dbExecute(con, create_table)
DBI::dbAppendTable(con, "el_matches", import)
DBI::dbDisconnect(con); rm(con)




# DBI::dbDisconnect(con); rm(con)


```


Update type info in `entites` depending on lobid data:

```{r}
# update entitites set person = 1, org = 0 where id in (....);
entity_types_from_lobid %>% filter(str_detect(external_id_desc, "Per")) %>% pull(id) %>% paste0(id, collapse = ",") %>% clipr::write_clip()

# update entitites set person = 0, org = 1 where id in (....);
entity_types_from_lobid %>% filter(str_detect(external_id_desc, "Body")) %>% pull(id) %>%  paste0("'", ., "'", collapse=", ")  %>% clipr::write_clip()
```

